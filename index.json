[{"content":"","date":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":null,"permalink":"/","section":"Silvio","summary":"","title":"Silvio"},{"content":"","date":null,"permalink":"/tags/iot/","section":"Tags","summary":"","title":"IoT"},{"content":"","date":null,"permalink":"/tags/programming/","section":"Tags","summary":"","title":"Programming"},{"content":"This article is to demonstrate how to program an Arduino Nano 33 IoT board to communicate with Microsoft Azure. With a quick Google search, you would find out that there\u0026rsquo;s already a library with all the functions required to share messages between Azure and Arduino boards. It is called AzureIoTHub and is the IoT Hub\u0026rsquo;s official Arduino library, published by Azure as a port of the Microsoft Azure IoT device SDK for C). The problem is that it doesn\u0026rsquo;t actually support any Arduino board. Looking at the README.md file, the hardware currently supported is:\nESP8266 based boards with esp8266/arduino\nSparkFun Thing\nAdafruit Feather Huzzah\nESP32 based boards with espressif/arduino-esp32\nAdafruit HUZZAH32 So, until the next compatibility update, the only way to send telemetry from a Nano 33 IoT to Azure IoT Hub is through third-party libraries.\nPrerequisites #To code my workaround, I used the following libraries:\nArduinoJson - To encapsulate my data in a JSON message, one of the formats accepted by IoT Hub;\nWiFiNINA - To connect the board to the WiFi;\nArduinoMqttClient - Client that allows to send and receive MQTT messages;\nArduinoBearSSL - Port of BearSSL to Arduino, to implement the SSL/TLS protocol;\nArduinoECCX08 - Library for the Atmel/Microchip ECC508 and ECC608 crypto chips, used for authentication with IoT Hub with a SelfSigned X.509 certificate;\nAll libraries must be installed on your system before compiling the code (instructions on how to install Arduino libraries can be found here).\nImplementation #Unfortunately, it\u0026rsquo;s not that easy. Turns out that in the first version of my code, I could successfully send short messages over Serial and MQTT. But, when I tried to send a JSON text bigger than 256 Bytes (i.e. longer than 256 characters), it arrived at the Hub truncated.\nScreenshot of the Azure Cloud Shell when receiving a truncated message. A similar issue is documented here, using a different library for the MQTT client. In that case, the advised solution is to change the value ENTER VALUE TO CHANGE from 256 to 2048, but that implies the following things:\nyou\u0026rsquo;d have to edit the library source code, so your program is not reproducible on other systems; you still set a fixed value, which, even if bigger, it\u0026rsquo;s not scalable. Azure Cloud Shell when the hub is receiving the correct message. Instead, the solution explained here doesn\u0026rsquo;t require any modification of the libraries\u0026rsquo; source code, since all the changes are made inside the sketch. Concretely, in the publishMessage() function, we declare the char array named payload, which acts as a temporary buffer to store the JSON document. Then, using serializeJson(), the document is serialized to the buffer and the function returns the number of bytes written, which is stored in payloadSize.\nchar payload[1024]; // length of the char buffer that contains the JSON file, concretely the number of characters included in one message size_t payloadSize = serializeJson(doc, payload); Now that we have the message and its size, we can send it via MQTT protocol to the IoT Hub. Through the overloaded function beginMessage() we pass the topic and the message size. Then, using the Print class implemented in ArduinoMqttClient, the JSON document is passed directly in the message body. Finally, the endMessage() function publishes the document to the specified topic.\n// send message, the Print interface can be used to set the message contents mqttClient.beginMessage(\u0026#34;devices/\u0026#34; + deviceId + \u0026#34;/messages/events/\u0026#34;, static_cast\u0026lt;unsigned long\u0026gt;(payloadSize)); mqttClient.print(payload); mqttClient.endMessage(); The complete function, as found in the example code, is the following:\nvoid publishMessage() { Serial.println(\u0026#34;Publishing message\u0026#34;); const int capacity = JSON_ARRAY_SIZE(10) + 10*JSON_OBJECT_SIZE(2)+ JSON_OBJECT_SIZE(3) + 280; // Calculation of the JSON doc size, as explained in the documentation /* Here is where you should write the body of your message. In this example, the JSON doc is purposely longer than 256 characters, to highlight the issue. */ StaticJsonDocument\u0026lt;capacity\u0026gt; doc; doc[\u0026#34;topic\u0026#34;] = \u0026#34;messageTopic\u0026#34;; doc[\u0026#34;deviceId\u0026#34;] = deviceId; JsonArray data = doc.createNestedArray(\u0026#34;data\u0026#34;); JsonObject data_0 = data.createNestedObject(); data_0[\u0026#34;label\u0026#34;] = \u0026#34;Ankara\u0026#34;; data_0[\u0026#34;state\u0026#34;] = true; JsonObject data_1 = data.createNestedObject(); data_1[\u0026#34;label\u0026#34;] = \u0026#34;Beirut\u0026#34;; data_1[\u0026#34;state\u0026#34;] = true; JsonObject data_2 = data.createNestedObject(); data_2[\u0026#34;label\u0026#34;] = \u0026#34;Cincinnati\u0026#34;; data_2[\u0026#34;state\u0026#34;] = false; JsonObject data_3 = data.createNestedObject(); data_3[\u0026#34;label\u0026#34;] = \u0026#34;Detroit\u0026#34;; data_3[\u0026#34;state\u0026#34;] = false; JsonObject data_4 = data.createNestedObject(); data_4[\u0026#34;label\u0026#34;] = \u0026#34;Eindhoven\u0026#34;; data_4[\u0026#34;state\u0026#34;] = true; JsonObject data_5 = data.createNestedObject(); data_5[\u0026#34;label\u0026#34;] = \u0026#34;Fresno\u0026#34;; data_5[\u0026#34;state\u0026#34;] = false; JsonObject data_6 = data.createNestedObject(); data_6[\u0026#34;label\u0026#34;] = \u0026#34;Genoa\u0026#34;; data_6[\u0026#34;state\u0026#34;] = false; JsonObject data_7 = data.createNestedObject(); data_7[\u0026#34;label\u0026#34;] = \u0026#34;Huddersfield\u0026#34;; data_7[\u0026#34;state\u0026#34;] = true; JsonObject data_8 = data.createNestedObject(); data_8[\u0026#34;label\u0026#34;] = \u0026#34;Istanbul\u0026#34;; data_8[\u0026#34;state\u0026#34;] = true; JsonObject data_9 = data.createNestedObject(); data_9[\u0026#34;label\u0026#34;] = \u0026#34;Jakarta\u0026#34;; data_9[\u0026#34;state\u0026#34;] = false; // DEBUG - serialize the document in the serial monitor // serializeJson(doc, Serial); // Serial.println(\u0026#34; \u0026#34;); char payload[1024]; // length of the char buffer that contains the JSON file, concretely the number of characters included in one message size_t payloadSize = serializeJson(doc, payload); // DEBUG - write the size of the serialized document // Serial.print(\u0026#34;json size:\u0026#34;); // Serial.println(payloadSize); // send message, the Print interface can be used to set the message contents mqttClient.beginMessage(\u0026#34;devices/\u0026#34; + deviceId + \u0026#34;/messages/events/\u0026#34;, static_cast\u0026lt;unsigned long\u0026gt;(payloadSize)); mqttClient.print(payload); mqttClient.endMessage(); /* To replicate the issue, uncomment the following 3 lines and comment the 3 above. This way you\u0026#39;ll only be able to send MQTT messages smaller than 256 Bytes. */ // mqttClient.beginMessage(\u0026#34;devices/\u0026#34; + deviceId + \u0026#34;/messages/events/\u0026#34;); // serializeJson(doc, mqttClient); // mqttClient.endMessage(); } The function above creates a JSON document as follows. Obviously, it can be changed as needed, this is an example to highlight the issue, since the text is longer than 256 characters.\n{ \u0026#34;topic\u0026#34;: \u0026#34;messageTopic\u0026#34;, \u0026#34;deviceId\u0026#34;: \u0026#34;deviceId\u0026#34;, \u0026#34;data\u0026#34;: [ { \u0026#34;label\u0026#34;: \u0026#34;Ankara\u0026#34;, \u0026#34;state\u0026#34;: true }, { \u0026#34;label\u0026#34;: \u0026#34;Beirut\u0026#34;, \u0026#34;state\u0026#34;: true }, { \u0026#34;label\u0026#34;: \u0026#34;Cincinnati\u0026#34;, \u0026#34;state\u0026#34;: false }, { \u0026#34;label\u0026#34;: \u0026#34;Detroit\u0026#34;, \u0026#34;state\u0026#34;: false }, { \u0026#34;label\u0026#34;: \u0026#34;Eindhoven\u0026#34;, \u0026#34;state\u0026#34;: true }, { \u0026#34;label\u0026#34;: \u0026#34;Fresno\u0026#34;, \u0026#34;state\u0026#34;: false }, { \u0026#34;label\u0026#34;: \u0026#34;Genoa\u0026#34;, \u0026#34;state\u0026#34;: false }, { \u0026#34;label\u0026#34;: \u0026#34;Huddersfield\u0026#34;, \u0026#34;state\u0026#34;: true }, { \u0026#34;label\u0026#34;: \u0026#34;Istanbul\u0026#34;, \u0026#34;state\u0026#34;: true }, { \u0026#34;label\u0026#34;: \u0026#34;Jakarta\u0026#34;, \u0026#34;state\u0026#34;: false } ] } I hope that this post was helpful. I uploaded an example of the code to send large JSON data from an Arduino Nano 33 IoT to Azure IoT Hub to a GitHub repository. Follow the instructions in the README.md to configure it properly. Feel free to use it, modify it and extend it as you like. Thanks for reading!\n","date":"24 August 2020","permalink":"/posts/large-json-data/","section":"Posts","summary":"How to program an Arduino 33 IoT board to communicate with Microsoft Azure, through IoT Hub and Stream Analytics. In particular, I explain a workaround to send JSON files bigger than 256 B.","title":"Send Large JSON Data to IoT Hub Using MQTT"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"","date":null,"permalink":"/tags/3d-printing/","section":"Tags","summary":"","title":"3D Printing"},{"content":"","date":null,"permalink":"/tags/acoustics/","section":"Tags","summary":"","title":"Acoustics"},{"content":"This post is on a project made at the beginning 2020 in which I had to analyse and mitigate the noise emitted by a desktop 3D printer. Here I cover the methodology used to conduct the measurements, which differs a bit from the standards, given the limited equipment available.\nTL;DR #To evaluate the structure-borne sound, the only calibrated instrument I could find was an old, single-axis vibration sensor, without the option to collect either octave band or one-third-octave band measurements. After 336 individual measures (144 with the vibration sensor + 144 with a contact microphone + 48 with NTi Audio sound level meters) carried on during a stressful 72 hours period, the results showed that the changes applied to the machine improved its noise emission. However, part of the instrumentation used (the CM-01B contact microphone) proved unsuitable for conducting the measuring process.\nMethodology #Test routines - I coded four G-Code procedures for tests reproducibility, numbered to match the name conventions on the collected data. Obviously, routine 1 and 2 do not require any G-Code file, since the 3D printer is not moving.\nBackground noise; Source idling; Source with simulated load, under normal working conditions (test-routine-a.gcode); Source at maximum operating speed (test-routine-c-full-speed.gcode); Source working under conditions corresponding to maximum sound generation representative of normal use (specimen-d-infill-only.gcode); Source undergoing a charateristic work cycle (specimen.gcode); Structure-borne sound - As I said previously, this set of tests couldn\u0026rsquo;t be conducted according to the standard BS ISO 9611:1996, but I tried to follow the procedure as far as possible. I collected 3-axis measurements on each of the 4 predefined supports and for each routine, using both the contact microphone CM-01B and the vibration meter Bruel \u0026amp; Kjaer 2537: the former returned Z-weighted sound pressure level in one-thirdoctave bands (from 20 Hz to 20 kHz), while the latter a single acceleration value. Both were time-averaged over each routine duration.\nSetup to measure structure-borne sound on the z-axis. Airborne sound - On the other hand, I could perform this tests according to BS EN ISO 1680:2013 and BS EN ISO 3746:2010. For this test, I conducted 6 measurements at each of the 4 microphone positions outlined by the standards, before and after the changes. The collected data were A-weighted sound pressure levels in one-third-octave-bands (from 20 Hz to 20 kHz), time-averaged over the routine average duration.\nMachine Survey and Improvements #After the first analysis and measurement session, the printer showed the following weaknesses in terms of noise emission:\nFans - Even without a systematic measurement, it is clear that the majority of the noise in a 3D printer comes from its fans. In particular, this machine has 4 fans in total, positioned in the following spots: motherboard, extruder, x-axis motor and power supply. The latter was the most problematic, since that fan was always running at full speed. This was caused by the power supply circuit, which has the space dedicated to a mechanical thermostat, but the component was removed and the poles jumped. So, I installed a normally open KSD9700 thermostat in the location and placed inside the large coil. The switch on the thermostat is designed to close if the temperature exceeds 45 degrees Celsius, which is a default con\fguration for this type of power supply. Position of the switching thermostat installed in the power supply. Motor dampers - The printer under test uses 5 Nema17 stepper motors, which is one of the most common and cheap solutions in the field. Despite their cost, popularity, and performance, these motors are particularly loud, especially when coupled with low resolution controllers like the DRV8825 IC. To address this potential issue, I decided to install mechanical dampers between the motor and the 3D printer frame. Installation of the motor dampers. Bearings - Another potential source of noise and vibration was found in the linear bearings of the y-axis. These three bearings allow the heated bed to move without friction along the cylindrical rails. In the original design of the printer, they were spherical bearings, which require lower tolerances to work, but are prone to lose performance over time. They have been substituted by self-lubricating polymer bearing, which have no moving parts, and therefore are quieter, more precise and durable. Results #All considered, this project is satisfactory: the data show improvements in most of the tested modes. After processing the raw data according to the relative standards, I plotted the before/after comparisons. Moreover, I\u0026rsquo;ve found out that a CM-01B contact microphone can\u0026rsquo;t be used to collect reliable vibration data!\nComparison between the data collected with the CM-01B for the y-axis. Apart from this finding, the other procedures show significant improvements on the noise emitted by the 3D printer. As you can se by the following graph, I was able to isolate and reduce specific frequencies in the machine (in this example, the peak at around 1000 Hz corresponds to cooling fan of the power supply).\nAirborne sound power level for test routine a. Thanks for reading! In case you want to take a deeper look at this project and at the results, you can find it here.\n","date":"18 June 2020","permalink":"/posts/noise-3d-printer/","section":"Posts","summary":"To evaluate the structure-borne sound, the only calibrated instrument I could find was an old, single-axis vibration sensor. After 336 individual measures carried on during a stressful 72 hours period, I can show you the results.","title":"Noise and Vibration Analysis of 3D Printers"},{"content":"This blog post is to summarise a research project conducted at the beginning of 2019 as part of the Advanced Audio Engineering module (MSc Audio Engineering, Leeds Beckett University). The project discusses the potential of achieving high performance in terms of sound absorption through additive manufacturing techniques.\nThe absorbers are designed to exploit the principle of passive destructive interference (PDI) and manufactured using a commercially available fused deposition modeling (FDM) 3D printer. The specimen are cylindrical and produced with cavities of different lengths. The absorption coefficient is evaluated using an impedance tube and following the specifications of the standard BS EN ISO 10534-2:2001.\nThe results show that significant sound absorption can be achieved, although some absorption peaks do not match the expected frequencies. This may be caused by turbulence and resonance phenomena, especially in samples with greater diameter of the cavity. Futher investigation is required, but the potential of these technologies in terms of efficiency over manufacturing cost and absorber size is undoubted.\nIntroduction #The aim of the project is to design and manufacture Passive Destructive Interference (PDI) absorbers using Additive Manufacturing (AM) techniques and then to evaluate their performance through a low cost, self-built impedance tube. The main outcome of the measurement process is a set of diagrams of the normal absorption factor of the specimens as a function of frequency in a mid-low spectrum range. The sound absorption curves will be then analyzed to determine the effects of the tested geometries and to verify if the experimental results agree with the values expected from the samples in the design phase.\nTheory and Methodology #The investigated devices are designed to absorb specific frequencies through passive destructive interference. These frequencies depend mainly on the specimen\u0026rsquo;s geometry, and can be calculated in advance through the following equation\n$$f_n = \\frac{(2n - 1)* c}{2L}$$\nwhere L (m) is the length of the cavity and c (m/s) is the speed of sound in the air.\nSpecification and design of a specimen. I designed the samples in SolidWorks and manufactured with an AthorBot Brother Desktop 3D Printer. To test different materials, both geometries were printed in ABS and PETG.\nTwo specimen used for measurement. The measurement of the absorption coefficient was conducted according to the two-micophone technique detailed in BS EN ISO 10534-2:2001. The biggest issue faced in this project was to find an impedance tube to conduct the evaluation. Since my university had part of the equipment (microphones, soundcard, speakers\u0026hellip;), in the end I decided to build a low-cost impedance tube. I built it out of pvc pipes, hydraulic seals, and I added an Arduino Uno with an OLED display and temperature/humidity sensors to keep track of the environmental conditions. To calibrate the tube and conduct the measuring process - which consisted in measuring the cross-transfer function and then calculating the absorption coefficient - I used the software Holmarc Wave Analyzer 4C .\nMeasurement test equipment layout. Findings #For each specimen, measurements are taken in the frequency interval 100-3200 Hz. The normal sound absorption curves are analysed through the evaluation of two values:\nThe frequency of peak sound absorption The frequency range between the values on both sides of the peak where half the peak sound absorption occurs. Using those values, the effects of the tested geometries can be determined and compared to the expected theoretical values. The results show that significant sound absorption has been achieved. The sound absorption coefficient reaches values of 0.87 at peak frequencies in the range considered. However, it must be noted that the absorption bandwidth is relatively narrow and that many relatively lower peaks can be attributed to the unprofessional measuring equipment.\nFor example, the following figure shows that the predicted frequency of the peaks for sample A is respected mainly in the lower range, while they are slightly shifted in the mid-upper range considered, probably due to production defects in the specimen.\nMeasured absorption coefficient for sample A compared to predicted peak frequencies. Thanks for reading! If you want to have a look at the full article, you can find it here.\nReferences # Sound absorption and additive manufacturing\nImplications of solid freeform fabrication on acoustic absorbers\n","date":"10 June 2020","permalink":"/posts/3d-printed-absorbers/","section":"Posts","summary":"An investigation on the potential of achieving high performance in terms of sound absorption through additive manufacturing techniques. I built a low-cost impedance tube, too.","title":"3D Printed Acoustic Absorbers"},{"content":"","date":null,"permalink":"/tags/electronics/","section":"Tags","summary":"","title":"Electronics"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/categories/chiptune/","section":"Categories","summary":"","title":"Chiptune"},{"content":"","date":null,"permalink":"/tags/music/","section":"Tags","summary":"","title":"Music"},{"content":"","date":null,"permalink":"/categories/music/","section":"Categories","summary":"","title":"Music"},{"content":" IMPORTANT NOTICE #Unfortunately, due to the Covid-19 pandemic, this project is currently paused. The reason is that I had to leave my house in Leeds and temporarily return to my hometown in Italy, leaving most of my stuff in the UK. I really hope to go back as soon as possible and continue this journey.\nDo More, with Less #For those unfamiliar with the term, chiptune (also known as chipmusic, micromusic or 8-bit music) is a style of electronic music derived from the sound chips that, in the first generation of computers and gaming consoles, were used to balance the processing power of generating sound effects and music from the CPU.\nThe primal micromusic spirit was to overcome limitations and wield them in wildly creative ways. - Fabio \u0026ldquo;Kenobit\u0026rdquo; Bortolotti\nLike everything nowadays, that definition can be interpreted in many ways. In its strictiest meaning, chiptune is used to refer to music created entirely from the original, vintage audio chips (nevertheless, modifications that do not alter the nature of the sound produced are \u0026ldquo;allowed\u0026rdquo;, but we\u0026rsquo;ll come back to this later). On the other hand, the broadest definition is more related to the aesthetics of the sound, rather then to the source generating it. In general, the philosophy behind the chiptune movement is to exploit the limited resources of the hardware to create more and more articulated music.\nDMG-01 #With its four audio channels, the Game Boy is supposedly the most popular tool for the production of micromusic. This console has been around for quite some time (Nintendo released it in 1989), and over the course of the years many people created and documented mods to equip it with useful features for the cause, such as better audio, rechargeable battery, backlit screen\u0026hellip;\nChannel Type Features 1 Pulse Volume envelope, 4-mode pulse width, frequency register from C3 upwards, frequency envelope 2 Pulse Volume envelope, 4-mode pulse width, frequency register from C3 upwards 3 Wave User-definable waveforms, bank of 32 samples (4-bit each), frequency register from C2 upwards 4 Noise White and brown noise What I want to do with this project is to use some of these mods as a starting point to transform that portable device into a proper music production tool, without over-denaturing its essence.\nFirst Design #Initially, I started this project as a university assignment, which is why I was able to document everything in detail (specifically, in this Github repo). Back then, my idea was to tear apart a Game Boy, rewire it from the inside to a different controls and put everything into a new, original case.\n3D model made with SolidWorks to show the exploded view of the final product. Unfortunately, towards the end of the semester I realised that creating a custom shell for my product was a task way harder than expected. So, after many stressful weeks, I decided - in accordance with my lecturers - to give up with the enclosure and present only a working prototype. Anyway, the exam went well, but I still want to bring this project to an end.\nReferences #Collins, K. and Kapralos, B. and Tessler, H. and Paul, J. L. (2014) The Oxford Handbook of Interactive Audio. Oxford: Oxford University Press.\n","date":"31 May 2020","permalink":"/posts/volca-boy-1/","section":"Posts","summary":"Just a brief introduction of the project, focusing on its components and the initial design.","title":"volca_boy[1] // Initial Design"},{"content":" IMPORTANT NOTICE #Unfortunately, due to the Covid-19 pandemic, this project is currently paused. The reason is that I had to leave my house in Leeds and temporarily return to my hometown in Italy, leaving most of my stuff in the UK. I really hope to go back as soon as possible and continue this journey.\nVolca Boy is a modding project aimed at turning a 1989 Game Boy into a portable synthesizer/sequencer. Although most of the work is original and designed by me, I borrowed some mods and code from other open source projects. In that case, I will give all the necessary credits to the modders from which I borrowed. This project is open source too, so feel free to try it, modify it, add and remove things to it as you like.\nThe links will appear as the project progresses and the steps get documented.\nIntro Mods Overview Software Hardware - Electrical Hardware - Case Demo ","date":"3 May 2020","permalink":"/posts/volca-boy-0/","section":"Posts","summary":"A modding project aimed at turning a 1989 Game Boy into a portable synthesizer/sequencer. The product will be based on the Korg volca Series form factor, and aims at unlocking cyberpunk functionalities into the chiptune realm.","title":"volca_boy[0] // Project Summary"},{"content":"","date":null,"permalink":"/tags/deep-learning/","section":"Tags","summary":"","title":"Deep Learning"},{"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":"27 April 2016","permalink":"/now/","section":"Silvio","summary":"An example of using the in-built project page.","title":"Example Project"},{"content":"","date":null,"permalink":"","section":"","summary":"","title":""},{"content":"I am a R\u0026amp;D engineer at GP2 developing a system for real-time monitoring and predictive maintenance of buildings and infrastructures. My primary functions are something in between a data scientist, software developer and embedded engineer.\nIn 2019, I decided to move from Brescia (Italy) to Leeds (United Kingdom) to study. I graduated a year later with a MSc in Audio Engineering, with a thesis on speech recognition for low power applications.\nNow, I am looking for opportunities to develop my professional career. Being passionate about music, video games, research and artificial intelligence, I want to make a real impact by collaborating on exciting and fulfilling projects that bring together creativity and advanced technologies.\n","date":null,"permalink":"","section":"","summary":"I am a R\u0026amp;D engineer at GP2 developing a system for real-time monitoring and predictive maintenance of buildings and infrastructures.","title":"Silvio Gregorini"}]