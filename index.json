[{"authors":null,"categories":null,"content":"I am a R\u0026amp;D engineer at GP2 developing a system for real-time monitoring and predictive maintenance of buildings and infrastructures. My primary functions are something in between a data scientist, software developer and embedded engineer.\nIn 2019, I decided to move from Brescia (Italy) to Leeds (United Kingdom) to study. I graduated a year later with a MSc in Audio Engineering, with a thesis on speech recognition for low power applications.\nNow, I am looking for opportunities to develop my professional career. Being passionate about music, video games, research and artificial intelligence, I want to make a real impact by collaborating on exciting and fulfilling projects that bring together creativity and advanced technologies.\n  Download my curriculum vitae.\n","date":1590948110,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1590948110,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a R\u0026amp;D engineer at GP2 developing a system for real-time monitoring and predictive maintenance of buildings and infrastructures. My primary functions are something in between a data scientist, software developer and embedded engineer.","tags":null,"title":"Silvio Gregorini","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://s-gregorini003.github.io/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":null,"categories":null,"content":"This article is to demonstrate how to program an Arduino Nano 33 IoT board to communicate with Microsoft Azure. With a quick Google search, you would find out that there\u0026rsquo;s already a library with all the functions required to share messages between Azure and Arduino boards. It is called AzureIoTHub and is the IoT Hub\u0026rsquo;s official Arduino library, published by Azure as a port of the Microsoft Azure IoT device SDK for C). The problem is that it doesn\u0026rsquo;t actually support any Arduino board. Looking at the README.md file, the hardware currently supported is:\n  ESP8266 based boards with esp8266/arduino\n  SparkFun Thing\n  Adafruit Feather Huzzah\n    ESP32 based boards with espressif/arduino-esp32\n Adafruit HUZZAH32    So, until the next compatibility update, the only way to send telemetry from a Nano 33 IoT to Azure IoT Hub is through third-party libraries.\nPrerequisites To code my workaround, I used the following libraries:\n  ArduinoJson - To encapsulate my data in a JSON message, one of the formats accepted by IoT Hub;\n  WiFiNINA - To connect the board to the WiFi;\n  ArduinoMqttClient - Client that allows to send and receive MQTT messages;\n  ArduinoBearSSL - Port of BearSSL to Arduino, to implement the SSL/TLS protocol;\n  ArduinoECCX08 - Library for the Atmel/Microchip ECC508 and ECC608 crypto chips, used for authentication with IoT Hub with a SelfSigned X.509 certificate;\n  All libraries must be installed on your system before compiling the code (instructions on how to install Arduino libraries can be found here).\nImplementation Unfortunately, it\u0026rsquo;s not that easy. Turns out that in the first version of my code, I could successfully send short messages over Serial and MQTT. But, when I tried to send a JSON text bigger than 256 Bytes (i.e. longer than 256 characters), it arrived at the Hub truncated.\n  Screenshot of the Azure Cloud Shell when receiving a truncated message.  A similar issue is documented here, using a different library for the MQTT client. In that case, the advised solution is to change the value ENTER VALUE TO CHANGE from 256 to 2048, but that implies the following things:\n you\u0026rsquo;d have to edit the library source code, so your program is not reproducible on other systems; you still set a fixed value, which, even if bigger, it\u0026rsquo;s not scalable.    Azure Cloud Shell when the hub is receiving the correct message.  Instead, the solution explained here doesn\u0026rsquo;t require any modification of the libraries' source code, since all the changes are made inside the sketch. Concretely, in the publishMessage() function, we declare the char array named payload, which acts as a temporary buffer to store the JSON document. Then, using serializeJson(), the document is serialized to the buffer and the function returns the number of bytes written, which is stored in payloadSize.\nchar payload[1024]; // length of the char buffer that contains the JSON file, concretely the number of characters included in one message\rsize_t payloadSize = serializeJson(doc, payload);\r Now that we have the message and its size, we can send it via MQTT protocol to the IoT Hub. Through the overloaded function beginMessage() we pass the topic and the message size. Then, using the Print class implemented in ArduinoMqttClient, the JSON document is passed directly in the message body. Finally, the endMessage() function publishes the document to the specified topic.\n// send message, the Print interface can be used to set the message contents\rmqttClient.beginMessage(\u0026quot;devices/\u0026quot; + deviceId + \u0026quot;/messages/events/\u0026quot;, static_cast\u0026lt;unsigned long\u0026gt;(payloadSize));\rmqttClient.print(payload);\rmqttClient.endMessage();\r The complete function, as found in the example code, is the following:\nvoid publishMessage() {\rSerial.println(\u0026quot;Publishing message\u0026quot;);\rconst int capacity = JSON_ARRAY_SIZE(10) + 10*JSON_OBJECT_SIZE(2)+ JSON_OBJECT_SIZE(3) + 280; // Calculation of the JSON doc size, as explained in the documentation\r/* Here is where you should write the body of your message. In this example, the JSON doc is purposely longer than 256 characters, to highlight the issue.\r*/\rStaticJsonDocument\u0026lt;capacity\u0026gt; doc;\rdoc[\u0026quot;topic\u0026quot;] = \u0026quot;messageTopic\u0026quot;; doc[\u0026quot;deviceId\u0026quot;] = deviceId;\rJsonArray data = doc.createNestedArray(\u0026quot;data\u0026quot;);\rJsonObject data_0 = data.createNestedObject();\rdata_0[\u0026quot;label\u0026quot;] = \u0026quot;Ankara\u0026quot;;\rdata_0[\u0026quot;state\u0026quot;] = true;\rJsonObject data_1 = data.createNestedObject();\rdata_1[\u0026quot;label\u0026quot;] = \u0026quot;Beirut\u0026quot;;\rdata_1[\u0026quot;state\u0026quot;] = true;\rJsonObject data_2 = data.createNestedObject();\rdata_2[\u0026quot;label\u0026quot;] = \u0026quot;Cincinnati\u0026quot;;\rdata_2[\u0026quot;state\u0026quot;] = false;\rJsonObject data_3 = data.createNestedObject();\rdata_3[\u0026quot;label\u0026quot;] = \u0026quot;Detroit\u0026quot;;\rdata_3[\u0026quot;state\u0026quot;] = false;\rJsonObject data_4 = data.createNestedObject();\rdata_4[\u0026quot;label\u0026quot;] = \u0026quot;Eindhoven\u0026quot;;\rdata_4[\u0026quot;state\u0026quot;] = true;\rJsonObject data_5 = data.createNestedObject();\rdata_5[\u0026quot;label\u0026quot;] = \u0026quot;Fresno\u0026quot;;\rdata_5[\u0026quot;state\u0026quot;] = false;\rJsonObject data_6 = data.createNestedObject();\rdata_6[\u0026quot;label\u0026quot;] = \u0026quot;Genoa\u0026quot;;\rdata_6[\u0026quot;state\u0026quot;] = false;\rJsonObject data_7 = data.createNestedObject();\rdata_7[\u0026quot;label\u0026quot;] = \u0026quot;Huddersfield\u0026quot;;\rdata_7[\u0026quot;state\u0026quot;] = true;\rJsonObject data_8 = data.createNestedObject();\rdata_8[\u0026quot;label\u0026quot;] = \u0026quot;Istanbul\u0026quot;;\rdata_8[\u0026quot;state\u0026quot;] = true;\rJsonObject data_9 = data.createNestedObject();\rdata_9[\u0026quot;label\u0026quot;] = \u0026quot;Jakarta\u0026quot;;\rdata_9[\u0026quot;state\u0026quot;] = false;\r// DEBUG - serialize the document in the serial monitor\r// serializeJson(doc, Serial);\r// Serial.println(\u0026quot; \u0026quot;);\rchar payload[1024]; // length of the char buffer that contains the JSON file, concretely the number of characters included in one message\rsize_t payloadSize = serializeJson(doc, payload);\r// DEBUG - write the size of the serialized document\r// Serial.print(\u0026quot;json size:\u0026quot;);\r// Serial.println(payloadSize);\r// send message, the Print interface can be used to set the message contents\rmqttClient.beginMessage(\u0026quot;devices/\u0026quot; + deviceId + \u0026quot;/messages/events/\u0026quot;, static_cast\u0026lt;unsigned long\u0026gt;(payloadSize));\rmqttClient.print(payload);\rmqttClient.endMessage();\r/* To replicate the issue, uncomment the following 3 lines and comment the 3 above. This way you'll only be able to send MQTT messages smaller than 256 Bytes.\r*/\r// mqttClient.beginMessage(\u0026quot;devices/\u0026quot; + deviceId + \u0026quot;/messages/events/\u0026quot;);\r// serializeJson(doc, mqttClient);\r// mqttClient.endMessage();\r}\r The function above creates a JSON document as follows. Obviously, it can be changed as needed, this is an example to highlight the issue, since the text is longer than 256 characters.\n{\r\u0026quot;topic\u0026quot;: \u0026quot;messageTopic\u0026quot;,\r\u0026quot;deviceId\u0026quot;: \u0026quot;deviceId\u0026quot;,\r\u0026quot;data\u0026quot;: [\r{\r\u0026quot;label\u0026quot;: \u0026quot;Ankara\u0026quot;,\r\u0026quot;state\u0026quot;: true\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Beirut\u0026quot;,\r\u0026quot;state\u0026quot;: true\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Cincinnati\u0026quot;,\r\u0026quot;state\u0026quot;: false\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Detroit\u0026quot;,\r\u0026quot;state\u0026quot;: false\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Eindhoven\u0026quot;,\r\u0026quot;state\u0026quot;: true\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Fresno\u0026quot;,\r\u0026quot;state\u0026quot;: false\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Genoa\u0026quot;,\r\u0026quot;state\u0026quot;: false\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Huddersfield\u0026quot;,\r\u0026quot;state\u0026quot;: true\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Istanbul\u0026quot;,\r\u0026quot;state\u0026quot;: true\r},\r{\r\u0026quot;label\u0026quot;: \u0026quot;Jakarta\u0026quot;,\r\u0026quot;state\u0026quot;: false\r}\r]\r}\r  I hope that this post was helpful. I uploaded an example of the code to send large JSON data from an Arduino Nano 33 IoT to Azure IoT Hub to a GitHub repository. Follow the instructions in the README.md to configure it properly. Feel free to use it, modify it and extend it as you like. Thanks for reading!\n","date":1598261488,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598261488,"objectID":"527dc9dab67b0a0b0be4c6dbccf9d7c3","permalink":"https://s-gregorini003.github.io/post/large-json-data/","publishdate":"2020-08-24T09:31:28Z","relpermalink":"/post/large-json-data/","section":"post","summary":"How to program an Arduino 33 IoT board to communicate with Microsoft Azure, through IoT Hub and Stream Analytics. In particular, I explain a workaround to send JSON files bigger than 256 B.","tags":["Programming","IoT"],"title":"Send Large JSON Data to IoT Hub Using MQTT","type":"post"},{"authors":null,"categories":null,"content":"This post is on a project made at the beginning 2020 in which I had to analyse and mitigate the noise emitted by a desktop 3D printer. Here I cover the methodology used to conduct the measurements, which differs a bit from the standards, given the limited equipment available.\nTL;DR To evaluate the structure-borne sound, the only calibrated instrument I could find was an old, single-axis vibration sensor, without the option to collect either octave band or one-third-octave band measurements. After 336 individual measures (144 with the vibration sensor + 144 with a contact microphone + 48 with NTi Audio sound level meters) carried on during a stressful 72 hours period, the results showed that the changes applied to the machine improved its noise emission. However, part of the instrumentation used (the CM-01B contact microphone) proved unsuitable for conducting the measuring process.\n Methodology Test routines - I coded four G-Code procedures for tests reproducibility, numbered to match the name conventions on the collected data. Obviously, routine 1 and 2 do not require any G-Code file, since the 3D printer is not moving.\n Background noise; Source idling; Source with simulated load, under normal working conditions (test-routine-a.gcode); Source at maximum operating speed (test-routine-c-full-speed.gcode); Source working under conditions corresponding to maximum sound generation representative of normal use (specimen-d-infill-only.gcode); Source undergoing a charateristic work cycle (specimen.gcode);  Structure-borne sound - As I said previously, this set of tests couldn\u0026rsquo;t be conducted according to the standard BS ISO 9611:1996, but I tried to follow the procedure as far as possible. I collected 3-axis measurements on each of the 4 predefined supports and for each routine, using both the contact microphone CM-01B and the vibration meter Bruel \u0026amp; Kjaer 2537: the former returned Z-weighted sound pressure level in one-thirdoctave bands (from 20 Hz to 20 kHz), while the latter a single acceleration value. Both were time-averaged over each routine duration.\n  Setup to measure structure-borne sound on the z-axis.  Airborne sound - On the other hand, I could perform this tests according to BS EN ISO 1680:2013 and BS EN ISO 3746:2010. For this test, I conducted 6 measurements at each of the 4 microphone positions outlined by the standards, before and after the changes. The collected data were A-weighted sound pressure levels in one-third-octave-bands (from 20 Hz to 20 kHz), time-averaged over the routine average duration.\nMachine Survey and Improvements After the first analysis and measurement session, the printer showed the following weaknesses in terms of noise emission:\n Fans - Even without a systematic measurement, it is clear that the majority of the noise in a 3D printer comes from its fans. In particular, this machine has 4 fans in total, positioned in the following spots: motherboard, extruder, x-axis motor and power supply. The latter was the most problematic, since that fan was always running at full speed. This was caused by the power supply circuit, which has the space dedicated to a mechanical thermostat, but the component was removed and the poles jumped. So, I installed a normally open KSD9700 thermostat in the location and placed inside the large coil. The switch on the thermostat is designed to close if the temperature exceeds 45 degrees Celsius, which is a default con\u000cguration for this type of power supply.    Position of the switching thermostat installed in the power supply.   Motor dampers - The printer under test uses 5 Nema17 stepper motors, which is one of the most common and cheap solutions in the field. Despite their cost, popularity, and performance, these motors are particularly loud, especially when coupled with low resolution controllers like the DRV8825 IC. To address this potential issue, I decided to install mechanical dampers between the motor and the 3D printer frame.    Installation of the motor dampers.   Bearings - Another potential source of noise and vibration was found in the linear bearings of the y-axis. These three bearings allow the heated bed to move without friction along the cylindrical rails. In the original design of the printer, they were spherical bearings, which require lower tolerances to work, but are prone to lose performance over time. They have been substituted by self-lubricating polymer bearing, which have no moving parts, and therefore are quieter, more precise and durable.  Results All considered, this project is satisfactory: the data show improvements in most of the tested modes. After processing the raw data according to the relative standards, I plotted the before/after comparisons. Moreover, I\u0026rsquo;ve found out that a CM-01B contact microphone can\u0026rsquo;t be used to collect reliable vibration data!\n  Comparison between the data collected with the CM-01B for the y-axis.  Apart from this finding, the other procedures show significant improvements on the noise emitted by the 3D printer. As you can se by the following graph, I was able to isolate and reduce specific frequencies in the machine (in this example, the peak at around 1000 Hz corresponds to cooling fan of the power supply).\n  Airborne sound power level for test routine a.   Thanks for reading! In case you want to take a deeper look at this project and at the results, you can find it here.\n","date":1592469942,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592469942,"objectID":"4fec15f12e628f291b2e409a134d66e2","permalink":"https://s-gregorini003.github.io/project/noise-3d-printer/","publishdate":"2020-06-18T08:45:42Z","relpermalink":"/project/noise-3d-printer/","section":"project","summary":"To evaluate the structure-borne sound, the only calibrated instrument I could find was an old, single-axis vibration sensor. After 336 individual measures carried on during a stressful 72 hours period, I can show you the results.","tags":["Acoustics","3D Printing"],"title":"Noise and Vibration Analysis of 3D Printers","type":"project"},{"authors":null,"categories":null,"content":"This blog post is to summarise a research project conducted at the beginning of 2019 as part of the Advanced Audio Engineering module (MSc Audio Engineering, Leeds Beckett University). The project discusses the potential of achieving high performance in terms of sound absorption through additive manufacturing techniques.\nThe absorbers are designed to exploit the principle of passive destructive interference (PDI) and manufactured using a commercially available fused deposition modeling (FDM) 3D printer. The specimen are cylindrical and produced with cavities of different lengths. The absorption coefficient is evaluated using an impedance tube and following the specifications of the standard BS EN ISO 10534-2:2001.\nThe results show that significant sound absorption can be achieved, although some absorption peaks do not match the expected frequencies. This may be caused by turbulence and resonance phenomena, especially in samples with greater diameter of the cavity. Futher investigation is required, but the potential of these technologies in terms of efficiency over manufacturing cost and absorber size is undoubted.\n Introduction The aim of the project is to design and manufacture Passive Destructive Interference (PDI) absorbers using Additive Manufacturing (AM) techniques and then to evaluate their performance through a low cost, self-built impedance tube. The main outcome of the measurement process is a set of diagrams of the normal absorption factor of the specimens as a function of frequency in a mid-low spectrum range. The sound absorption curves will be then analyzed to determine the effects of the tested geometries and to verify if the experimental results agree with the values expected from the samples in the design phase.\nTheory and Methodology The investigated devices are designed to absorb specific frequencies through passive destructive interference. These frequencies depend mainly on the specimen\u0026rsquo;s geometry, and can be calculated in advance through the following equation\n$$f_n = \\frac{(2n - 1)* c}{2L}$$\nwhere L (m) is the length of the cavity and c (m/s) is the speed of sound in the air.\n  Specification and design of a specimen.  I designed the samples in SolidWorks and manufactured with an AthorBot Brother Desktop 3D Printer. To test different materials, both geometries were printed in ABS and PETG.\n  Two specimen used for measurement.  The measurement of the absorption coefficient was conducted according to the two-micophone technique detailed in BS EN ISO 10534-2:2001. The biggest issue faced in this project was to find an impedance tube to conduct the evaluation. Since my university had part of the equipment (microphones, soundcard, speakers\u0026hellip;), in the end I decided to build a low-cost impedance tube. I built it out of pvc pipes, hydraulic seals, and I added an Arduino Uno with an OLED display and temperature/humidity sensors to keep track of the environmental conditions. To calibrate the tube and conduct the measuring process - which consisted in measuring the cross-transfer function and then calculating the absorption coefficient - I used the software Holmarc Wave Analyzer 4C .\n  Measurement test equipment layout.  Findings For each specimen, measurements are taken in the frequency interval 100-3200 Hz. The normal sound absorption curves are analysed through the evaluation of two values:\n The frequency of peak sound absorption The frequency range between the values on both sides of the peak where half the peak sound absorption occurs.  Using those values, the effects of the tested geometries can be determined and compared to the expected theoretical values. The results show that significant sound absorption has been achieved. The sound absorption coefficient reaches values of 0.87 at peak frequencies in the range considered. However, it must be noted that the absorption bandwidth is relatively narrow and that many relatively lower peaks can be attributed to the unprofessional measuring equipment.\nFor example, the following figure shows that the predicted frequency of the peaks for sample A is respected mainly in the lower range, while they are slightly shifted in the mid-upper range considered, probably due to production defects in the specimen.\n  Measured absorption coefficient for sample A compared to predicted peak frequencies.   Thanks for reading! If you want to have a look at the full article, you can find it here.\nReferences   Sound absorption and additive manufacturing\n  Implications of solid freeform fabrication on acoustic absorbers\n  ","date":1591778742,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591778742,"objectID":"ee16fe2315e7ff396b12f13a6fbfcfb9","permalink":"https://s-gregorini003.github.io/project/3d-printed-absorbers/","publishdate":"2020-06-10T08:45:42Z","relpermalink":"/project/3d-printed-absorbers/","section":"project","summary":"An investigation on the potential of achieving high performance in terms of sound absorption through additive manufacturing techniques. I built a low-cost impedance tube, too.","tags":["Acoustics","3D Printing","Electronics"],"title":"3D Printed Acoustic Absorbers","type":"project"},{"authors":["Silvio Gregorini"],"categories":["Chiptune","Music"],"content":" IMPORTANT NOTICE Unfortunately, due to the Covid-19 pandemic, this project is currently paused. The reason is that I had to leave my house in Leeds and temporarily return to my hometown in Italy, leaving most of my stuff in the UK. I really hope to go back as soon as possible and continue this journey.\n Do More, with Less For those unfamiliar with the term, chiptune (also known as chipmusic, micromusic or 8-bit music) is a style of electronic music derived from the sound chips that, in the first generation of computers and gaming consoles, were used to balance the processing power of generating sound effects and music from the CPU.\n The primal micromusic spirit was to overcome limitations and wield them in wildly creative ways. - Fabio \u0026ldquo;Kenobit\u0026rdquo; Bortolotti\n Like everything nowadays, that definition can be interpreted in many ways. In its strictiest meaning, chiptune is used to refer to music created entirely from the original, vintage audio chips (nevertheless, modifications that do not alter the nature of the sound produced are \u0026ldquo;allowed\u0026rdquo;, but we\u0026rsquo;ll come back to this later). On the other hand, the broadest definition is more related to the aesthetics of the sound, rather then to the source generating it. In general, the philosophy behind the chiptune movement is to exploit the limited resources of the hardware to create more and more articulated music.\nDMG-01 With its four audio channels, the Game Boy is supposedly the most popular tool for the production of micromusic. This console has been around for quite some time (Nintendo released it in 1989), and over the course of the years many people created and documented mods to equip it with useful features for the cause, such as better audio, rechargeable battery, backlit screen\u0026hellip;\n   Channel Type Features     1 Pulse Volume envelope, 4-mode pulse width, frequency register from C3 upwards, frequency envelope   2 Pulse Volume envelope, 4-mode pulse width, frequency register from C3 upwards   3 Wave User-definable waveforms, bank of 32 samples (4-bit each), frequency register from C2 upwards   4 Noise White and brown noise    What I want to do with this project is to use some of these mods as a starting point to transform that portable device into a proper music production tool, without over-denaturing its essence.\nFirst Design Initially, I started this project as a university assignment, which is why I was able to document everything in detail (specifically, in this Github repo). Back then, my idea was to tear apart a Game Boy, rewire it from the inside to a different controls and put everything into a new, original case.\n  3D model made with SolidWorks to show the exploded view of the final product.  Unfortunately, towards the end of the semester I realised that creating a custom shell for my product was a task way harder than expected. So, after many stressful weeks, I decided - in accordance with my lecturers - to give up with the enclosure and present only a working prototype. Anyway, the exam went well, but I still want to bring this project to an end.\nReferences Collins, K. and Kapralos, B. and Tessler, H. and Paul, J. L. (2014) The Oxford Handbook of Interactive Audio. Oxford: Oxford University Press.\n","date":1590948110,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590948110,"objectID":"0352e0bca1fc785a45f8ada1628952bb","permalink":"https://s-gregorini003.github.io/post/volca-boy-1/","publishdate":"2020-05-31T18:01:50Z","relpermalink":"/post/volca-boy-1/","section":"post","summary":"Just a brief introduction of the project, focusing on its components and the initial design.","tags":["Music","Electronics","Programming"],"title":"volca_boy[1] // Initial Design","type":"post"},{"authors":null,"categories":["Chiptune","Music"],"content":" IMPORTANT NOTICE Unfortunately, due to the Covid-19 pandemic, this project is currently paused. The reason is that I had to leave my house in Leeds and temporarily return to my hometown in Italy, leaving most of my stuff in the UK. I really hope to go back as soon as possible and continue this journey.\n Volca Boy is a modding project aimed at turning a 1989 Game Boy into a portable synthesizer/sequencer. Although most of the work is original and designed by me, I borrowed some mods and code from other open source projects. In that case, I will give all the necessary credits to the modders from which I borrowed. This project is open source too, so feel free to try it, modify it, add and remove things to it as you like.\nThe links will appear as the project progresses and the steps get documented.\n Intro Mods Overview Software Hardware - Electrical Hardware - Case Demo  ","date":1588522426,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588522426,"objectID":"5a29b54dd7329b7f59ad8de87236c331","permalink":"https://s-gregorini003.github.io/project/volca-boy-0/","publishdate":"2020-05-03T16:13:46Z","relpermalink":"/project/volca-boy-0/","section":"project","summary":"A modding project aimed at turning a 1989 Game Boy into a portable synthesizer/sequencer. The product will be based on the Korg volca Series form factor, and aims at unlocking cyberpunk functionalities into the chiptune realm.","tags":["Music","Electronics","Programming"],"title":"volca_boy[0] // Project Summary","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://s-gregorini003.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Silvio Gregorini","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"https://s-gregorini003.github.io/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://s-gregorini003.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]